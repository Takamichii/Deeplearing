{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Takamichii/Deeplearing/blob/main/code_Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpoxEc921y62"
      },
      "source": [
        "## How to Build a Code Editing Agent\n",
        "\n",
        "Adapted from Source - https://ampcode.com/how-to-build-an-agent by Thorsten Ball"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU together"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kF5GfXdi2HmQ",
        "outputId": "37ea12b4-ea99-4ef7-f6a6-6025eadc4842"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/88.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.7/88.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQBnAIE51y63"
      },
      "outputs": [],
      "source": [
        "from together import Together\n",
        "client = Together()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Looping LLM Call = Chat"
      ],
      "metadata": {
        "id": "UtO9CeGt4OSB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLTjMB_h1y64",
        "outputId": "28e1614f-7fa7-4ff0-8be4-2f0abc9f20eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter something (type 'exit' to quit): hello!\n",
            "You entered: hello!\n",
            "LLM Response: Hello! How can I assist you today?\n",
            "Enter something (type 'exit' to quit): exit\n"
          ]
        }
      ],
      "source": [
        "messages_history = []\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"Enter something (type 'exit' to quit): \")\n",
        "    if user_input.lower() == 'exit':\n",
        "        break\n",
        "    messages_history.append({\"role\": \"user\", \"content\": user_input})\n",
        "    print(f\"You entered: {user_input}\")\n",
        "    # Process user_input here\n",
        "    completion = client.chat.completions.create(\n",
        "    model=\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n",
        "    messages = messages_history,\n",
        "    )\n",
        "    print(f\"LLM Response: {completion.choices[0].message.content}\")\n",
        "    messages_history.append({\"role\": \"assistant\", \"content\": completion.choices[0].message.content})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7fegSJr1y64"
      },
      "outputs": [],
      "source": [
        "def chat():\n",
        "    while True:\n",
        "        user_input = input(\"Enter something (type 'exit' to quit): \")\n",
        "        if user_input.lower() == 'exit':\n",
        "            break\n",
        "        messages_history.append({\"role\": \"user\", \"content\": user_input})\n",
        "        print(f\"You entered: {user_input}\")\n",
        "        # Process user_input here\n",
        "        completion = client.chat.completions.create(\n",
        "        model=\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n",
        "        messages = messages_history,\n",
        "        )\n",
        "        print(f\"LLM Response: {completion.choices[0].message.content}\")\n",
        "        messages_history.append({\"role\": \"assistant\", \"content\": completion.choices[0].message.content})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpBpQDXO1y64",
        "outputId": "a4e1d683-2fa3-4cd1-f78e-1cd1f6e1902d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter something (type 'exit' to quit): hello what model is this?\n",
            "You entered: hello what model is this?\n",
            "LLM Response: I'm an AI, and my model is based on a range of technologies and algorithms developed by Meta AI. I'm a large language model, specifically a variant of the Llama model (Large Language Model Meta AI).\n",
            "Enter something (type 'exit' to quit): exit\n"
          ]
        }
      ],
      "source": [
        "chat()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## First we create a tool that allows LLMs to read files!"
      ],
      "metadata": {
        "id": "On4QnWNz4S-N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iO_w2hAv1y65"
      },
      "outputs": [],
      "source": [
        "def read_file(path: str) -> str:\n",
        "    \"\"\"\n",
        "    Reads the content of a file and returns it as a string.\n",
        "\n",
        "    Args:\n",
        "        path: The relative path of a file in the working directory.\n",
        "\n",
        "    Returns:\n",
        "        The content of the file as a string.\n",
        "\n",
        "    Raises:\n",
        "        FileNotFoundError: If the specified file does not exist.\n",
        "        PermissionError: If the user does not have permission to read the file.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(path, 'r', encoding='utf-8') as file:\n",
        "            content = file.read()\n",
        "\n",
        "        return content\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        raise FileNotFoundError(f\"The file '{path}' was not found.\")\n",
        "    except PermissionError:\n",
        "        raise PermissionError(f\"You don't have permission to read '{path}'.\")\n",
        "    except Exception as e:\n",
        "        raise Exception(f\"An error occurred while reading '{path}': {str(e)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8hFuRWj1y65"
      },
      "outputs": [],
      "source": [
        "read_file_schema = {'type': 'function',\n",
        " 'function': {'name': 'read_file',\n",
        "  'description': 'The relative path of a file in the working directory.',\n",
        "  'parameters': {'properties': {'path': {'description': 'The relative path of a file in the working directory.',\n",
        "     'title': 'Path',\n",
        "     'type': 'string'}},\n",
        "   'type': 'object'}}}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"my favourite colour is dodger blue\" > secret.txt"
      ],
      "metadata": {
        "id": "e2McppZi17pe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function Calling: Step 1 - Let LLM Call Tools"
      ],
      "metadata": {
        "id": "W1o5nQBE2sGV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gj4fMp751y65"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant that can access external functions. The responses from these function calls will be appended to this dialogue. Please provide responses based on the information from these function calls.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Read the file secret.txt and reveal the secret!\"}\n",
        "]\n",
        "tools = [read_file_schema]\n",
        "\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"Qwen/Qwen2.5-7B-Instruct-Turbo\",\n",
        "    messages=messages,\n",
        "    tools=tools,\n",
        "    tool_choice=\"auto\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Extract the tool call"
      ],
      "metadata": {
        "id": "DWLD4nND3Osm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(json.dumps(response.choices[0].message.model_dump()['tool_calls'], indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUGZL0io3N9B",
        "outputId": "e56b2528-7ec4-498b-c95f-21a26f2283f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "  {\n",
            "    \"id\": \"call_wu8yp358uf88dya46b39pwju\",\n",
            "    \"type\": \"function\",\n",
            "    \"function\": {\n",
            "      \"name\": \"read_file\",\n",
            "      \"arguments\": \"{\\\"path\\\":\\\"secret.txt\\\"}\"\n",
            "    },\n",
            "    \"index\": 0\n",
            "  }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3 & 4: Execute Tool and Append Output"
      ],
      "metadata": {
        "id": "Rdy9Jq123SWH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FO-MSjP_1y65",
        "outputId": "1a73d0e6-3015-47cc-e6a0-373d113739d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tool name: read_file, Tool response: my favourite colour is dodger blue\n",
            "\n"
          ]
        }
      ],
      "source": [
        "tool_calls = response.choices[0].message.tool_calls\n",
        "\n",
        "if tool_calls:\n",
        "    for tool_call in tool_calls:\n",
        "        function_name = tool_call.function.name\n",
        "        function_args = json.loads(tool_call.function.arguments)\n",
        "\n",
        "        if function_name == \"read_file\":\n",
        "            function_response = read_file(\n",
        "                path=function_args.get(\"path\")\n",
        "            )\n",
        "            messages.append(\n",
        "                {\n",
        "                    \"tool_call_id\": tool_call.id,\n",
        "                    \"role\": \"tool\",\n",
        "                    \"name\": function_name,\n",
        "                    \"content\": function_response,\n",
        "                }\n",
        "            )\n",
        "            print(f\"Tool name: {function_name}, Tool response: {function_response}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Final Response w/ Tool Output"
      ],
      "metadata": {
        "id": "rQOCPITM3nI5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "function_enriched_response = client.chat.completions.create(\n",
        "        model=\"Qwen/Qwen2.5-7B-Instruct-Turbo\",\n",
        "        messages=messages,\n",
        "    )\n",
        "\n",
        "print(json.dumps(function_enriched_response.choices[0].message.model_dump(), indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtdWbCbH3mlJ",
        "outputId": "49a6cd7e-fda6-4aba-ac7b-a52f143ada61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"role\": \"assistant\",\n",
            "  \"content\": \"The secret from the file secret.txt is \\\"my favourite colour is dodger blue\\\".\",\n",
            "  \"tool_calls\": []\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## All together now!"
      ],
      "metadata": {
        "id": "wSvogUkR4g6a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_vbtHVK1y65"
      },
      "outputs": [],
      "source": [
        "def chat():\n",
        "    messages_history = []\n",
        "    while True:\n",
        "        user_input = input(\"Enter something (type 'exit' to quit): \")\n",
        "        if user_input.lower() == 'exit':\n",
        "            break\n",
        "\n",
        "        messages_history.append({\"role\": \"user\", \"content\": user_input})\n",
        "        print(f\"You: {user_input}\")\n",
        "\n",
        "        # Process user_input here\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"Qwen/Qwen2.5-7B-Instruct-Turbo\",\n",
        "            messages=messages_history,\n",
        "            tools=tools,\n",
        "            tool_choice=\"auto\",\n",
        "        )\n",
        "\n",
        "        # if tool called handle it\n",
        "        tool_calls = response.choices[0].message.tool_calls\n",
        "        if tool_calls:\n",
        "            for tool_call in tool_calls:\n",
        "                function_name = tool_call.function.name\n",
        "                function_args = json.loads(tool_call.function.arguments)\n",
        "\n",
        "                if function_name == \"read_file\":\n",
        "                    function_response = read_file(\n",
        "                        path=function_args.get(\"path\")\n",
        "                    )\n",
        "                    messages_history.append(\n",
        "                        {\n",
        "                            \"tool_call_id\": tool_call.id,\n",
        "                            \"role\": \"tool\",\n",
        "                            \"name\": function_name,\n",
        "                            \"content\": function_response,\n",
        "                        }\n",
        "                    )\n",
        "\n",
        "                    function_enriched_response = client.chat.completions.create(\n",
        "                        model=\"Qwen/Qwen2.5-7B-Instruct-Turbo\",\n",
        "                        messages=messages_history,\n",
        "                        )\n",
        "\n",
        "                    messages_history.append({\"role\": \"assistant\", \"content\": function_enriched_response.choices[0].message.content})\n",
        "                    print(f\"LLM: {function_enriched_response.choices[0].message.content}\")\n",
        "        else:\n",
        "            messages_history.append({\"role\": \"assistant\", \"content\": response.choices[0].message.content})\n",
        "            print(f\"LLM: {response.choices[0].message.content}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CpxH3_XP1y65",
        "outputId": "dd66ef37-7862-4af9-fa4c-d21921f967db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You: hello\n",
            "LLM: Hello! How can I assist you today?\n",
            "You: My name is Zain!\n",
            "LLM: Hello Zain! Nice to meet you. Is there something specific you need help with today?\n",
            "You: Make a joke about my name\n",
            "LLM: Sure! Here's a joke for you: Why did Zain pack only one suitcase? Because he heard the airport had a \"Twin\" policy!\n",
            "You: Tell me the secret inside secret.txt\n",
            "LLM: The secret inside `secret.txt` is that your favorite color is \"cyan sanguine\"! Isn't that an interesting shade? It's a unique blend of cyan and a reddish-pink tone.\n",
            "You: nice!\n",
            "LLM: Glad you think so! If you have any other questions or need more secrets revealed, feel free to ask!\n"
          ]
        }
      ],
      "source": [
        "chat()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a tool that can list all files in directory"
      ],
      "metadata": {
        "id": "UHn_mfIY4z4w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OXxMWfO1y65"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "def list_files(path=\".\"):\n",
        "    \"\"\"\n",
        "    Lists all files and directories in the specified path.\n",
        "\n",
        "    Args:\n",
        "        path (str): The relative path of a directory in the working directory.\n",
        "                    Defaults to the current directory.\n",
        "\n",
        "    Returns:\n",
        "        str: A JSON string containing a list of files and directories.\n",
        "    \"\"\"\n",
        "    result = []\n",
        "    base_path = Path(path)\n",
        "\n",
        "    if not base_path.exists():\n",
        "        return json.dumps({\"error\": f\"Path '{path}' does not exist\"})\n",
        "\n",
        "    for root, dirs, files in os.walk(path):\n",
        "        root_path = Path(root)\n",
        "        rel_root = root_path.relative_to(base_path) if root_path != base_path else Path(\".\")\n",
        "\n",
        "        # Add directories with trailing slash\n",
        "        for dir_name in dirs:\n",
        "            rel_path = rel_root / dir_name\n",
        "            if str(rel_path) != \".\":\n",
        "                result.append(f\"{rel_path}/\")\n",
        "\n",
        "        # Add files\n",
        "        for file_name in files:\n",
        "            rel_path = rel_root / file_name\n",
        "            if str(rel_path) != \".\":\n",
        "                result.append(str(rel_path))\n",
        "\n",
        "    return json.dumps(result)\n",
        "\n",
        "list_files_schema = {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"list_files\",\n",
        "            \"description\": \"List all files and directories in the specified path.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"path\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The relative path of a directory in the working directory. Defaults to current directory.\"\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "# Register the list_files function in the tools\n",
        "tools.append(list_files_schema)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGonUi6S1y65"
      },
      "outputs": [],
      "source": [
        "list_files()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Give the LLM the ability to call this tool!"
      ],
      "metadata": {
        "id": "i56yhQQy5C5i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRed04dc1y65"
      },
      "outputs": [],
      "source": [
        "# Update the chat function to handle the list_files tool\n",
        "def chat():\n",
        "    messages_history = []\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() in [\"exit\", \"quit\", \"q\"]:\n",
        "            break\n",
        "\n",
        "        messages_history.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"Qwen/Qwen2.5-7B-Instruct-Turbo\",\n",
        "            messages=messages_history,\n",
        "            tools=tools,\n",
        "        )\n",
        "\n",
        "        tool_calls = response.choices[0].message.tool_calls\n",
        "        if tool_calls:\n",
        "            for tool_call in tool_calls:\n",
        "                function_name = tool_call.function.name\n",
        "                function_args = json.loads(tool_call.function.arguments)\n",
        "\n",
        "                if function_name == \"read_file\":\n",
        "                    function_response = read_file(\n",
        "                        path=function_args.get(\"path\")\n",
        "                    )\n",
        "                    messages_history.append(\n",
        "                        {\n",
        "                            \"tool_call_id\": tool_call.id,\n",
        "                            \"role\": \"tool\",\n",
        "                            \"name\": function_name,\n",
        "                            \"content\": function_response,\n",
        "                        }\n",
        "                    )\n",
        "                elif function_name == \"list_files\":\n",
        "                    function_response = list_files(\n",
        "                        path=function_args.get(\"path\", \".\")\n",
        "                    )\n",
        "                    messages_history.append(\n",
        "                        {\n",
        "                            \"tool_call_id\": tool_call.id,\n",
        "                            \"role\": \"tool\",\n",
        "                            \"name\": function_name,\n",
        "                            \"content\": function_response,\n",
        "                        }\n",
        "                    )\n",
        "\n",
        "                function_enriched_response = client.chat.completions.create(\n",
        "                    model=\"Qwen/Qwen2.5-7B-Instruct-Turbo\",\n",
        "                    messages=messages_history,\n",
        "                )\n",
        "\n",
        "                messages_history.append({\"role\": \"assistant\", \"content\": function_enriched_response.choices[0].message.content})\n",
        "                print(f\"LLM: {function_enriched_response.choices[0].message.content}\")\n",
        "        else:\n",
        "            messages_history.append({\"role\": \"assistant\", \"content\": response.choices[0].message.content})\n",
        "            print(f\"LLM: {response.choices[0].message.content}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example Run"
      ],
      "metadata": {
        "id": "I1hhfIfB50A8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ZcgS_Hi1y66",
        "outputId": "357f8965-8238-4d74-8e14-82403f7481ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LLM: The directory contains the following items:\n",
            "\n",
            "1. `secret-file.txt`\n",
            "2. `secret.txt`\n",
            "3. `How_to_Build_an_Agent.ipynb` (which likely refers to an IPython notebook or Jupyter notebook file)\n",
            "LLM: The directory contains two `.txt` files:\n",
            "\n",
            "1. `secret-file.txt`\n",
            "2. `secret.txt`\n",
            "LLM: Sure, let's take a brief look at the contents of each `.txt` file:\n",
            "\n",
            "1. **`secret-file.txt`**:\n",
            "   - *Contents:* Unfortunately, I don't have the actual content of this file. You can view it using the `read_file` function.\n",
            "\n",
            "2. **`secret.txt`**:\n",
            "   - *Contents:* Similarly, I don't have the actual content of this file. You can view it using the `read_file` function.\n",
            "\n",
            "Would you like me to read the contents of these files for you?\n"
          ]
        }
      ],
      "source": [
        "chat()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a tool that will let the LLM edit files!"
      ],
      "metadata": {
        "id": "ZfaLP1v15Ln8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vNZ8fW1B1y66"
      },
      "outputs": [],
      "source": [
        "def edit_file(path, old_str, new_str):\n",
        "    \"\"\"\n",
        "    Edit a file by replacing all occurrences of old_str with new_str.\n",
        "    If old_str is empty and the file doesn't exist, create a new file with new_str.\n",
        "\n",
        "    Args:\n",
        "        path (str): The relative path of the file to edit\n",
        "        old_str (str): The string to replace\n",
        "        new_str (str): The string to replace with\n",
        "\n",
        "    Returns:\n",
        "        str: \"OK\" if successful\n",
        "    \"\"\"\n",
        "\n",
        "    if not path or old_str == new_str:\n",
        "        raise ValueError(\"Invalid input parameters\")\n",
        "\n",
        "    try:\n",
        "        with open(path, 'r') as file:\n",
        "            old_content = file.read()\n",
        "    except FileNotFoundError:\n",
        "        if old_str == \"\":\n",
        "            # Create a new file if old_str is empty and file doesn't exist\n",
        "            with open(path, 'w') as file:\n",
        "                file.write(new_str)\n",
        "            return \"OK\"\n",
        "        else:\n",
        "            raise FileNotFoundError(f\"File not found: {path}\")\n",
        "\n",
        "    new_content = old_content.replace(old_str, new_str)\n",
        "\n",
        "    if old_content == new_content and old_str != \"\":\n",
        "        raise ValueError(\"old_str not found in file\")\n",
        "\n",
        "    with open(path, 'w') as file:\n",
        "        file.write(new_content)\n",
        "\n",
        "    return \"OK\"\n",
        "\n",
        "# Define the function schema for the edit_file tool\n",
        "edit_file_schema = {\n",
        "    \"type\": \"function\",\n",
        "    \"function\": {\n",
        "        \"name\": \"edit_file\",\n",
        "        \"description\": \"Edit a file by replacing all occurrences of a string with another string\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"path\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"The relative path of the file to edit\"\n",
        "                },\n",
        "                \"old_str\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"The string to replace (empty string for new files)\"\n",
        "                },\n",
        "                \"new_str\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"The string to replace with\"\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"path\", \"old_str\", \"new_str\"]\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# Update the tools list to include the edit_file function\n",
        "tools.append(edit_file_schema)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Give the LLM the ability to use the file edit tool!"
      ],
      "metadata": {
        "id": "_8rk5P_p5vaW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0ICzWf01y66"
      },
      "outputs": [],
      "source": [
        "# Update the chat function to handle the list_files and edit_file tools\n",
        "def chat():\n",
        "    messages_history = []\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() in [\"exit\", \"quit\", \"q\"]:\n",
        "            break\n",
        "\n",
        "        messages_history.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"Qwen/Qwen2.5-7B-Instruct-Turbo\",\n",
        "            messages=messages_history,\n",
        "            tools=tools,\n",
        "        )\n",
        "\n",
        "        tool_calls = response.choices[0].message.tool_calls\n",
        "        if tool_calls:\n",
        "            for tool_call in tool_calls:\n",
        "                function_name = tool_call.function.name\n",
        "                function_args = json.loads(tool_call.function.arguments)\n",
        "\n",
        "                if function_name == \"read_file\":\n",
        "                    print(f\"Tool call: read_file\")\n",
        "                    function_response = read_file(\n",
        "                        path=function_args.get(\"path\")\n",
        "                    )\n",
        "                    messages_history.append(\n",
        "                        {\n",
        "                            \"tool_call_id\": tool_call.id,\n",
        "                            \"role\": \"tool\",\n",
        "                            \"name\": function_name,\n",
        "                            \"content\": function_response,\n",
        "                        }\n",
        "                    )\n",
        "                elif function_name == \"list_files\":\n",
        "                    print(f\"Tool call: list_files\")\n",
        "                    function_response = list_files(\n",
        "                        path=function_args.get(\"path\", \".\")\n",
        "                    )\n",
        "\n",
        "                    messages_history.append(\n",
        "                        {\n",
        "                            \"tool_call_id\": tool_call.id,\n",
        "                            \"role\": \"tool\",\n",
        "                            \"name\": function_name,\n",
        "                            \"content\": function_response,\n",
        "                        }\n",
        "                    )\n",
        "                elif function_name == \"edit_file\":\n",
        "                    print(f\"Tool call: edit_file\")\n",
        "                    function_response = edit_file(\n",
        "                        path=function_args.get(\"path\"),\n",
        "                        old_str=function_args.get(\"old_str\"),\n",
        "                        new_str=function_args.get(\"new_str\")\n",
        "                    )\n",
        "                    messages_history.append(\n",
        "                        {\n",
        "                            \"tool_call_id\": tool_call.id,\n",
        "                            \"role\": \"tool\",\n",
        "                            \"name\": function_name,\n",
        "                            \"content\": function_response,\n",
        "                        }\n",
        "                    )\n",
        "\n",
        "                function_enriched_response = client.chat.completions.create(\n",
        "                    model=\"Qwen/Qwen2.5-7B-Instruct-Turbo\",\n",
        "                    messages=messages_history,\n",
        "                )\n",
        "\n",
        "                messages_history.append({\"role\": \"assistant\", \"content\": function_enriched_response.choices[0].message.content})\n",
        "                print(f\"LLM: {function_enriched_response.choices[0].message.content}\")\n",
        "        else:\n",
        "            messages_history.append({\"role\": \"assistant\", \"content\": response.choices[0].message.content})\n",
        "            print(f\"LLM: {response.choices[0].message.content}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example Run:"
      ],
      "metadata": {
        "id": "ewtIpzZJ55kM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGWqhOon1y66",
        "outputId": "3d6b6b4c-88a8-408b-e43d-1872763aaa49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tool call: edit_file\n",
            "LLM: Sure! Below is a simple `fizzbuzz.py` script that you can run with Python. This script will print numbers from 1 to 100, replacing numbers divisible by 3 with \"Fizz\", numbers divisible by 5 with \"Buzz\", and numbers divisible by both 3 and 5 with \"FizzBuzz\".\n",
            "\n",
            "```python\n",
            "# fizzbuzz.py\n",
            "\n",
            "def fizzbuzz():\n",
            "    for i in range(1, 101):\n",
            "        if i % 3 == 0 and i % 5 == 0:\n",
            "            print(\"FizzBuzz\")\n",
            "        elif i % 3 == 0:\n",
            "            print(\"Fizz\")\n",
            "        elif i % 5 == 0:\n",
            "            print(\"Buzz\")\n",
            "        else:\n",
            "            print(i)\n",
            "\n",
            "if __name__ == \"__main__\":\n",
            "    fizzbuzz()\n",
            "```\n",
            "\n",
            "To run this script, save it as `fizzbuzz.py` and then execute it using Python:\n",
            "\n",
            "```sh\n",
            "python fizzbuzz.py\n",
            "```\n",
            "\n",
            "This will output the FizzBuzz sequence from 1 to 100.\n"
          ]
        }
      ],
      "source": [
        "chat()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kyLhS1PE1y66",
        "outputId": "11694c49-e3c5-4814-9156-1d54c6f30931"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "Fizz\n",
            "4\n",
            "Buzz\n",
            "Fizz\n",
            "7\n",
            "8\n",
            "Fizz\n",
            "Buzz\n",
            "11\n",
            "Fizz\n",
            "13\n",
            "14\n",
            "FizzBuzz\n",
            "16\n",
            "17\n",
            "Fizz\n",
            "19\n",
            "Buzz\n",
            "Fizz\n",
            "22\n",
            "23\n",
            "Fizz\n",
            "Buzz\n",
            "26\n",
            "Fizz\n",
            "28\n",
            "29\n",
            "FizzBuzz\n",
            "31\n",
            "32\n",
            "Fizz\n",
            "34\n",
            "Buzz\n",
            "Fizz\n",
            "37\n",
            "38\n",
            "Fizz\n",
            "Buzz\n",
            "41\n",
            "Fizz\n",
            "43\n",
            "44\n",
            "FizzBuzz\n",
            "46\n",
            "47\n",
            "Fizz\n",
            "49\n",
            "Buzz\n",
            "Fizz\n",
            "52\n",
            "53\n",
            "Fizz\n",
            "Buzz\n",
            "56\n",
            "Fizz\n",
            "58\n",
            "59\n",
            "FizzBuzz\n",
            "61\n",
            "62\n",
            "Fizz\n",
            "64\n",
            "Buzz\n",
            "Fizz\n",
            "67\n",
            "68\n",
            "Fizz\n",
            "Buzz\n",
            "71\n",
            "Fizz\n",
            "73\n",
            "74\n",
            "FizzBuzz\n",
            "76\n",
            "77\n",
            "Fizz\n",
            "79\n",
            "Buzz\n",
            "Fizz\n",
            "82\n",
            "83\n",
            "Fizz\n",
            "Buzz\n",
            "86\n",
            "Fizz\n",
            "88\n",
            "89\n",
            "FizzBuzz\n",
            "91\n",
            "92\n",
            "Fizz\n",
            "94\n",
            "Buzz\n",
            "Fizz\n",
            "97\n",
            "98\n",
            "Fizz\n",
            "Buzz\n"
          ]
        }
      ],
      "source": [
        "!python fizzbuzz.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IeDDteKG1y66",
        "outputId": "01647a8c-5fc7-4794-8c1b-3b48e29b6879"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tool call: list_files\n",
            "LLM: The files present in the directory are:\n",
            "\n",
            "1. `fizzbuzz.py`\n",
            "2. `secret-file.txt`\n",
            "3. `secret.txt`\n",
            "4. `How_to_Build_an_Agent.ipynb` (which is likely a Jupyter Notebook file)\n",
            "Tool call: read_file\n",
            "LLM: The content of the `fizzbuzz.py` file is as follows:\n",
            "\n",
            "```python\n",
            "def fizzbuzz():\n",
            "    for i in range(1, 101):\n",
            "        if i % 3 == 0 and i % 5 == 0:\n",
            "            print('FizzBuzz')\n",
            "        elif i % 3 == 0:\n",
            "            print('Fizz')\n",
            "        elif i % 5 == 0:\n",
            "            print('Buzz')\n",
            "        else:\n",
            "            print(i)\n",
            "\n",
            "if __name__ == '__main__':\n",
            "    fizzbuzz()\n",
            "```\n",
            "\n",
            "This script defines a function `fizzbuzz` that prints numbers from 1 to 100, replacing numbers divisible by 3 with \"Fizz\", numbers divisible by 5 with \"Buzz\", and numbers divisible by both 3 and 5 with \"FizzBuzz\". The `if __name__ == '__main__':` block ensures that the `fizzbuzz` function is called when the script is executed directly.\n",
            "Tool call: edit_file\n",
            "LLM: Sure! I'll update the `fizzbuzz.py` file so that it only prints numbers from 1 to 15, following the same logic.\n",
            "\n",
            "Here is the updated content:\n",
            "\n",
            "```python\n",
            "def fizzbuzz():\n",
            "    for i in range(1, 16):\n",
            "        if i % 3 == 0 and i % 5 == 0:\n",
            "            print('FizzBuzz')\n",
            "        elif i % 3 == 0:\n",
            "            print('Fizz')\n",
            "        elif i % 5 == 0:\n",
            "            print('Buzz')\n",
            "        else:\n",
            "            print(i)\n",
            "\n",
            "if __name__ == '__main__':\n",
            "    fizzbuzz()\n",
            "```\n",
            "\n",
            "You can save this updated code in your `fizzbuzz.py` file. Here is the complete script again for clarity:\n",
            "\n",
            "```python\n",
            "def fizzbuzz():\n",
            "    for i in range(1, 16):\n",
            "        if i % 3 == 0 and i % 5 == 0:\n",
            "            print('FizzBuzz')\n",
            "        elif i % 3 == 0:\n",
            "            print('Fizz')\n",
            "        elif i % 5 == 0:\n",
            "            print('Buzz')\n",
            "        else:\n",
            "            print(i)\n",
            "\n",
            "if __name__ == '__main__':\n",
            "    fizzbuzz()\n",
            "```\n",
            "\n",
            "This will print numbers from 1 to 15, replacing the appropriate numbers with \"Fizz\", \"Buzz\", or \"FizzBuzz\" as per the rules.\n"
          ]
        }
      ],
      "source": [
        "chat()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UmEeC29g1y66",
        "outputId": "95ca12ee-4d53-4d5a-dbd6-b2840ed6541a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "Fizz\n",
            "4\n",
            "Buzz\n",
            "Fizz\n",
            "7\n",
            "8\n",
            "Fizz\n",
            "Buzz\n",
            "11\n",
            "Fizz\n",
            "13\n",
            "14\n",
            "FizzBuzz\n"
          ]
        }
      ],
      "source": [
        "!python fizzbuzz.py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Another Example Run:"
      ],
      "metadata": {
        "id": "_wstwbdw6Js8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mh3uXAXv1y66",
        "outputId": "905c0582-e539-412b-a0ee-82fb0b2b641e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tool call: edit_file\n",
            "LLM: Sure, I'll create a `congrats.py` script that rot13-decodes the given string and prints it. Here's the script:\n",
            "\n",
            "```python\n",
            "def rot13_decode(s):\n",
            "    result = \"\"\n",
            "    for char in s:\n",
            "        if 'a' <= char <= 'z':\n",
            "            start = ord('a')\n",
            "            offset = (ord(char) - start + 13) % 26\n",
            "            result += chr(start + offset)\n",
            "        elif 'A' <= char <= 'Z':\n",
            "            start = ord('A')\n",
            "            offset = (ord(char) - start + 13) % 26\n",
            "            result += chr(start + offset)\n",
            "        else:\n",
            "            result += char\n",
            "    return result\n",
            "\n",
            "# The encoded string\n",
            "encoded_string = 'Pbatenghyngvbaf ba ohvyqvat n pbqr-rqvgvat ntrag!'\n",
            "\n",
            "# Decoding the string\n",
            "decoded_string = rot13_decode(encoded_string)\n",
            "\n",
            "# Printing the decoded string\n",
            "print(decoded_string)\n",
            "```\n",
            "\n",
            "You can save this code in a file named `congrats.py` and run it to see the decoded message.\n"
          ]
        }
      ],
      "source": [
        "chat()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQ4dA8I-1y66",
        "outputId": "0588cb79-5b4b-4598-d6a7-9426392d6b25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Congratulations on building a code-editing agent!\n"
          ]
        }
      ],
      "source": [
        "!python congrats.py"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "cookbook",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}